{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"doj_songs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Data\n",
    "\n",
    "# merge all characters into one string\n",
    "text = \"\"\n",
    "clean = \"\"\n",
    "for line in songs[\"lyrics\"]:\n",
    "    text = text + str(line).lower()\n",
    "    clean = clean + \" \".join(re.findall(r\"[a-z']+\", text))\n",
    "\n",
    "# find all unique characters\n",
    "tokens = re.findall(r\"[a-z'\\s]\", clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Alphabet\n",
    "\n",
    "characters = sorted(list(set(tokens)))\n",
    "len(characters)\n",
    "# 28 unique characters\n",
    "\n",
    "# dictionary for character-to-index mapping\n",
    "char_to_index = dict((char, index) for index, char in enumerate(characters))\n",
    "\n",
    "# dictionary for index-to-character mapping\n",
    "index_to_char = dict((index, char) for index, char in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Sequences\n",
    "\n",
    "# chunk the text into sequences\n",
    "maxlen = 20  # n\n",
    "step = 1  # length of step at each iteration\n",
    "\n",
    "# list of sequences\n",
    "sequences = []\n",
    "\n",
    "# list of next characters model should predict\n",
    "next_characters = []\n",
    "\n",
    "# iterate over cleaned text string and each 20-length sequence into list\n",
    "for i in range(0, len(clean) - maxlen, step):\n",
    "    sequences.append(clean[i : (i + maxlen)])\n",
    "    next_characters.append(clean[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode Training Sequences (one-hot encoding)\n",
    "\n",
    "# create empty matrices for input and output sets\n",
    "# input: each n-length sequence in sequences list\n",
    "# output: next character after each n-length sequence\n",
    "# i.e.: sentence = \"hello there\"\n",
    "#       sequence = \"hel\"\n",
    "#       next char = \"l\"\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(characters)), dtype=np.bool_)  # input\n",
    "y = np.zeros((len(sequences), len(characters)), dtype=np.bool_)  # output\n",
    "\n",
    "for i, chunk in enumerate(sequences):\n",
    "    for j, c in enumerate(chunk):\n",
    "        x[i, j, char_to_index[c]] = 1\n",
    "    y[i, char_to_index[next_characters[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model\n",
    "A single LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-12 01:15:27.598922: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(characters))),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(len(characters), activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               80384     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                3612      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,996\n",
      "Trainable params: 83,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Text Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample an index from a probability array\n",
    "\n",
    "def sample(predictions, temperature=1.0):\n",
    "    predictions = np.asarray(predictions).astype(\"float64\")\n",
    "    predictions = np.log(predictions) / temperature\n",
    "    exp_predictions = np.exp(predictions)\n",
    "    predictions = exp_predictions / np.sum(exp_predictions)\n",
    "    probabilities = np.random.multinomial(1, predictions, 1)\n",
    "    return np.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19275/19275 [==============================] - 1245s 64ms/step - loss: 0.8150\n",
      "\n",
      "Generating text after epoch: 0\n",
      "Diversity:  0.5\n",
      "Generating with seed: 'if she won't go dijo'\n",
      "Generated:   lean and your hands down woman woman woman ayy i can be your woman woman woman woman ayy i can get believe i got a man but i want a man to stand and fight stand and fight for meging i have it ain't got your ganester ass me ath no got a h baby i how ain 't coldow ha om ain't gotta ally want me a to you boy i 'll show you yeah baby let me watch you go to town it's your one chaine a manted get into \n",
      "\n",
      "Diversity:  1.0\n",
      "Generating with seed: 'if she won't go dijo'\n",
      "Generated:  n do it like that saids from the nigga don't clean weth your deesed can give speak in the body but when the best come thatiggin' like this a diffim like vikendes something baby i wouldn't lie wiah wancust'  it's one me how love cknougd jealoe the tis with mydan when he tait ain't boss full my drank like the bed son 't bandes cars and lett the move you like that i want that one till we hew to prout\n",
      "\n",
      "Diversity:  1.2\n",
      "Generating with seed: 'if she won't go dijo'\n",
      "Generated:  n 'cause yoursw cuap griss 'bout to fuckin' backa woo shised turn yeah reen to you vibpide let now douge imalesto make relall the sine orenan get whow thot woman nomy kild nice with my hain and side up misty i me and thought the erping everythith just a starde nah no girash and the sealy your anyther h all me him you pite night in a fastasi gato like a tiol ove your whole i won 't bed fow i 'm kid\n",
      "\n",
      "19275/19275 [==============================] - 1262s 65ms/step - loss: 0.5502\n",
      "\n",
      "Generating text after epoch: 1\n",
      "Diversity:  0.5\n",
      "Generating with seed: 'u go to town go down'\n",
      "Generated:   go down let me leel with ans hold me when we want i can't believe my eyes and her more love an my somethin ' i might bit ha don 't wanna take you want me bad yeah baby when you talk to me i be in my bag i be in my bag when you talk dirty back na na na na na i 'm too i stand and you could see it from the front wait till you see it from the back back back back wait 'til you see it from the if you c\n",
      "\n",
      "Diversity:  1.0\n",
      "Generating with seed: 'u go to town go down'\n",
      "Generated:   go to town it 'se dirm fucks efolle frockin ' on them botsers i am whish fuckin ' your aly thound clong night for mecall just work you can daddia kayd or on them mery thighs yeah so gen it belren gubcatch do it 'til my dyught me when the mind you ain't read you wanna bet you do it motherfucke bitch since and i 'll uh pince you usgiction prolly cause i'm fancy uh oh ohh uh uh oh oh ohh you would t\n",
      "\n",
      "Diversity:  1.2\n",
      "Generating with seed: 'u go to town go down'\n",
      "Generated:   go down go down yeah let me see you touch y'bore how that 's ftie t probore holly lifer nouck bread in the just you run anyvits mible but blut lost just love it on me body had to the tron 't but the egging uh up and ad the needer gri likn my stick she loke that pipen of teld us baby heak when i don't even what you feel dod i ain't call on my vipin' more hows love yeah then zindsi i got him all bi\n",
      "\n",
      "19275/19275 [==============================] - 1136s 59ms/step - loss: 0.4695\n",
      "\n",
      "Generating text after epoch: 2\n",
      "Diversity:  0.5\n",
      "Generating with seed: 'he morning light lig'\n",
      "Generated:  ht light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light l\n",
      "\n",
      "Diversity:  1.0\n",
      "Generating with seed: 'he morning light lig'\n",
      "Generated:  ht light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light light l\n",
      "\n",
      "Diversity:  1.2\n",
      "Generating with seed: 'he morning light lig'\n",
      "Generated:  ht light light light light light light light light light light light light light light lenshike ottight ass getting the shargl night now i ain't a litta when you're for take him yo gri pope like you like thess maty do night morning irys butt you make it 's but i want a man but youf if that's mad boy down got the trpeast you there got me prolled monay pollin' misther mayby is like like vibs knew se\n",
      "\n",
      "19275/19275 [==============================] - 1053s 55ms/step - loss: 0.4339\n",
      "\n",
      "Generating text after epoch: 3\n",
      "Diversity:  0.5\n",
      "Generating with seed: 'now bitches you shou'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jl/scpv3h4s1gg9bhlvnrq23jxm0000gn/T/ipykernel_3303/4202515213.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  predictions = np.log(predictions) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  ld bring them hoes and bros with us and baby you can roll roll with us yeah roll roll with us and baby you can roll roll with us and baby you can roll roll with us and baby you can roll maybe you can roll roll with us yeah roll roll with us and baby you can roll roll with us and baby you can roll maybe you can roll roll with us yeah roll roll with us and baby you can roll maybe youg lost me like y\n",
      "\n",
      "Diversity:  1.0\n",
      "Generating with seed: 'now bitches you shou'\n",
      "Generated:  ld bring them hoes and bros with us all dodin ' what for egco opand in to to yourprerse that's just like that selfin' like i i i my trick my bottom bitch don't gin turn my lusbrsy with you ayy all shit crock like that it addice night with hure should be let we freak awon't toke niggas your pats now bitch ibcives one know i goun raoor goodnieg needer something bitches i'ma dirt eath she ain't got i\n",
      "\n",
      "Diversity:  1.2\n",
      "Generating with seed: 'now bitches you shou'\n",
      "Generated:  ldn speed so grinat baby up and in prill fuck no bloom players just mind get out and you mad 'bout it's your name big break in my hundr'e pleckep into chollin' could pelvere uh lown of foll five 't stop chatg ha get into it yuh and it's just crook me mijust in my eyes nownione weusid a tojafr and i pop even it don't git moniggin ' beaw i'll grenam got me like sipe that need she aourgp it huh in a \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    model.fit(x, y, batch_size = size, epochs=1)\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" %epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.5, 1.0, 1.2]:\n",
    "        print(\"Diversity: \", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = clean[start_index:start_index + maxlen]\n",
    "        print(\"Generating with seed: '\" + sentence + \"'\")\n",
    "\n",
    "        for i in range(400):\n",
    "            x_predict = np.zeros((1, maxlen, len(characters)))\n",
    "            \n",
    "            for t, char in enumerate(sentence):\n",
    "                x_predict[0, t, char_to_index[char]] = 1.0\n",
    "            predictions = model.predict(x_predict, verbose = 0)[0]\n",
    "            next_index = sample(predictions, diversity)\n",
    "            next_char = index_to_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"Generated: \", generated)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53106b8b7ed522358aa641d737ee42e62cb017b820976fe1f7061245382f143a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
